<!-- // inspired by https://github.com/kevmo314/magic-copy -->
<html>
  <head>
    <title></title>

    <script src="https://cdn.jsdelivr.net/npm/onnxruntime-web/dist/ort.min.js"></script>

    <script>


      async function main() {

        session = await ort.InferenceSession.create('./sam2.onnx');

        i1 = document.getElementById('i1');
        height = i1.height;
        width = i1.width;


        i1.onclick = handleclick;


      };

      topleft = null;
      bottomright = null;
      function handleclick(e) {

        console.log(e.clientX, e.clientY)

        el = e.target;
        rect = el.getBoundingClientRect();
        x = e.clientX - rect.left;
        y = e.clientY - rect.top;

        i1 = document.getElementById('i1');
        height = i1.height;
        width = i1.width;

        imageScale = width / el.offsetWidth;
        x *= imageScale;
        y *= imageScale;        

        if (!topleft) {
          topleft = [x, y];
          // console.log(topleft)
          return
        } 

        if (!bottomright) {
          bottomright = [x, y];
          // console.log(bottomright);

          x1 = topleft[0];
          y1 = topleft[1];
          x2 = bottomright[0];
          y2 = bottomright[1];

          console.log('a', x1, y1, x2, y2)

          letsgo(x1, y1, x2, y2);
        }
      }

      async function letsgo(x1, y1, x2, y2) {

          console.log('lets go')

          i1 = document.getElementById('i1');
          url = i1.src;




          // x1 = 0;
          // y1 = 0;
          // x2 = 140;
          // y2 = 140;
          mask = await segment(url, x1, y1, x2, y2);

          mask = arrayToImageData(mask.output.data, width, height);
          c1 = document.getElementById('c1');
          c1.width = width;
          c1.height = height;

          ctx = c1.getContext('2d');
          ctx.putImageData(mask, 0, 0);

      }       



      function arrayToImageData(input, width, height) {
        // From: https://github.com/facebookresearch/segment-anything/blob/40df6e4046d8b07ab8c4519e083408289eb43032/demo/src/components/helpers/maskUtils.tsx
        // Copyright (c) Meta Platforms, Inc. and affiliates.
        // All rights reserved.

        // This source code is licensed under the license found in the
        // LICENSE file in the root directory of this source tree.
        [r, g, b, a] = [0, 114, 189, 255]; // the masks's blue color
        arr = new Uint8ClampedArray(4 * width * height);
        for (var i = 0; i < input.length; i++) {

          // Threshold the onnx model mask prediction at 0.0
          // This is equivalent to thresholding the mask using predictor.model.mask_threshold
          // in python
          if (input[i] > 0.0) {
            arr[4 * i + 0] = r;
            arr[4 * i + 1] = g;
            arr[4 * i + 2] = b;
            arr[4 * i + 3] = a;
          }

        }
        
        return new ImageData(arr, width, height);

      };

      async function segment(url, x1, y1, x2, y2) {

        input = {};
        input['low_res_embedding'] = await get_embedding(url);

        // scaled coordinates

        // get_preprocess_shape
        scale = 1024 / Math.max(height, width);
        // new_h = Math.round(height*scale + 0.5)
        // new_w = Math.round(width*scale + 0.5)



        // // x1 = x1*scale;
        // // y1 = y1*scale;
        // // x2 = x2*scale;
        // // y2 = y2*scale;

        // x1 = x1*(new_w / width);
        // y1 = y1*(new_h / height);
        // x2 = x2*(new_w / width);
        // y2 = y2*(new_h / height);

        // console.log(scale, new_w/width, new_h/height)

        clicks = [[x1, y1], [x2, y2]]

        let n = clicks.length;

        // If there is no box input, a single padding point with 
        // label -1 and coordinates (0.0, 0.0) should be concatenated
        // so initialize the array to support (n + 1) points.
        pointCoords = new Float32Array(2 * (n + 1));
        pointLabels = new Float32Array(n + 1);

        // Add clicks and scale to what SAM expects
        for (let i = 0; i < n; i++) {
          pointCoords[2 * i] = clicks[i][0] * scale;
          pointCoords[2 * i + 1] = clicks[i][1] * scale;
          pointLabels[i] = clicks[i].clickType;
        }

        // Add in the extra point/label when only clicks and no box
        // The extra point is at (0, 0) with label -1
        pointCoords[2 * n] = 0.0;
        pointCoords[2 * n + 1] = 0.0;
        pointLabels[n] = -1.0;

        console.log(pointCoords)


        // pointCoords = new Float32Array(2 * (n + 2));
        // pointLabels = new Float32Array(n + 2);
        // pointCoords[0] = x1 / scale;
        // pointCoords[1] = y1 / scale;
        // pointLabels[0] = 2.0; // UPPER_LEFT
        // pointCoords[2] = x2 / scale;
        // pointCoords[3] = y2 / scale;
        // pointLabels[1] = 3.0; // BOTTOM_RIGHT

        // console.log(pointCoords)

        // Create the tensor
        pointCoordsTensor = new ort.Tensor("float32", pointCoords, [1, n + 1, 2]);
        pointLabelsTensor = new ort.Tensor("float32", pointLabels, [1, n + 1]);


        // input['point_coords'] = new ort.Tensor("float32", new Float32Array([x1,y1,x2,y2]), [1, 2, 2]);
        input['point_coords'] = pointCoordsTensor

        // 2 and 3 mean top-left-bottom-right box
        // input['point_labels'] = new ort.Tensor("float32", new Float32Array([2,3]), [1, 2]);
                input['point_labels'] = pointLabelsTensor

        // original image size
        input['image_size'] = new ort.Tensor("float32", new Float32Array([height, width]));

        // empty mask
        input['last_pred_mask'] = new ort.Tensor("float32", new Float32Array(256 * 256), [1, 1, 256, 256]);
        input['has_last_pred'] = new ort.Tensor("float32", new Float32Array([0]));
 
        return session.run( input ).then( output => {

          return output;

        }).catch(err => {

          console.error(err);

        });

      };

      async function get_embedding(url) {

        response = await fetch(url);
        blob = await response.blob();

        endpoint = 'https://model-zoo.metademolab.com/predictions/segment_everything_box_model';

        embedding = await fetch(endpoint, { method: "POST", body: blob }).then((response) => response.json());

        uint8arr = Uint8Array.from(atob(embedding[0]), (c) => c.charCodeAt(0));
        embedding = new ort.Tensor("float32", new Float32Array(uint8arr.buffer), [1, 256, 64, 64]);

        return embedding;

      };

      main();

    </script>

  </head>
  <body>

    <img id='i1' src='cat.png'>
    <canvas id='c1' style='border:solid black 1px;'>

  </body>
</html>
